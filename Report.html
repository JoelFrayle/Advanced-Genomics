---
title: "Report Advanced Genomics"
author: "Joel Frayle Moreno- Francesco Mazza"
date: "2026-02-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Project number 5: DNA replication introduces copy number variations that are detectable in RNA-seq

We have to install and run the required packages:

```{r packages, echo=FALSE}
#install.packages('lubridate')
pkgs <- c("dplyr","data.table","stringr","scales","tibble")
for (p in pkgs) if (!requireNamespace(p, quietly=TRUE)) install.packages(p)
library(dplyr); library(data.table); library(stringr); library(scales); library(tibble)
```

## FILE HANDLING 

First we read the datasets and then we explore them. 
expr_df is a collection of gene expression data for E. Coli generated through single cell RNA-seq analysis, and have been already normalized with logarithmic function; each colname represents the experiments, and the rownames represent the genes_identifier;
meta_df instead contains all the metadata related to each sample;


```{r file reading }

expr_df <- read.csv("log_tpm.csv", check.names = FALSE)  # first col = gene_id
meta_df <- read.csv("sample_table.csv", check.names = FALSE)
colnames(expr_df)[1:10]
colnames(meta_df)[1:10]
```

## Mapping
We retrieve the information from NCBI that give us the Genes, and the position in a linear sequence. This is going to help us later to set the position of each one of the genes in our dataset.

```{r file reading }
gff_url  <- "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gz"
gff_file <- "GCF_000005845.2_ASM584v2_genomic.gff.gz"
if (!file.exists(gff_file)) download.file(gff_url, gff_file, mode="wb")
gff <- fread(gff_file, sep="\t", header=FALSE, quote="", comment.char="#", fill=TRUE) #fread help us to manage the information from the NCBI File
setnames(gff, c("seqid","source","type","start","end","score","strand","phase","attr")) #We set some known names to the columns to manage more easy the 
table(gff$type) #We make some expoloration of the data in gff
```

## Extraction usefull information:
  we subset from gff, and we keep only the information for our specific case: gene_id, start and end position of each gene;
  as we need a circular chromosome, we need to compute the specific position; we set "pos" as the average of the start and end positions of each gene; 
  then we will approximate the position of each gene to these "pos" values.

```{r file reading }
gff <- gff[type == "gene"] #We remain just with the gene information
gff[, gene_id := sub(".*locus_tag=([^;]+).*", "\\1", attr)] #We extract from the NCBI attr the identificator of the gene that correspond to the name of the gene in our dataset
gff <- gff[, .(gene_id, start, end)]
typeof(gff$start)
gff[, start := as.integer(start)]
gff[, end   := as.integer(end)]    #We extract the positions of the gene
typeof(gff$start)
L <- max(gff$end, na.rm=TRUE) 
#Sets L to the maximum end coordinate on the main chromosome: 
#your estimate of the genome length (useful for building circular coordinates later). 
#L should be approximately the chromosome length (e.g., ~4.6e6 for E. coli K12).
gene_coords <- gff[grepl("^b\\d{4}$", gene_id),
                          .(gene_id, start, end, strand, pos=(start+end)/2)]
gene_coords <- unique(gene_coords, by="gene_id")
```


  
```{r file reading }
  ## 4) Map expression matrix to genes with coords
expr_gene_id <- expr_df[[1]] #Expression values themselves have no genomic meaning unless you know which gene each row corresponds to
#This vector becomes the backbone for joining expression ↔ coordinates
anyDuplicated(expr_gene_id) #0 ok! 
#“take genes in expression order, then attach coordinates if available.”
#check if there are NA in pos
unique(is.na(gene_coords$pos))
gene_info <- tibble(gene_id = expr_gene_id) %>%
  left_join(as.data.frame(gene_coords) %>% mutate(gene_id=as.character(gene_id)),
            by="gene_id")

expr_mat <- as.matrix(expr_df[, -1])
rownames(expr_mat) <- expr_df[[1]]
storage.mode(expr_mat) <- "numeric"
expr_mat2 <- expr_mat[gene_info$gene_id, , drop=FALSE]
```
#### 5) Bin genes + compute theta for bin midpoints
window_size <- 100000
#E. coli genome ≈ 4.6 Mb → ~46 bins This is a tradeoff:
   #Smaller bins → noisier but higher resolution
   #Larger bins → smoother but may wash out signal
#check
L / window_size    #46.41628
gene_info <- gene_info %>%
  mutate(
    pos_mod   = pos %% L,
    bin       = floor(pos_mod / window_size),
    bin_mid   = ((bin + 0.5) * window_size) %% L,
    theta_bin = 2*pi*bin_mid/L
  )
#y = α + β cos(θ) + γ sin(θ)
#You’re now modeling expression as a sinusoid over the genome.

idx_by_bin <- split(seq_len(nrow(gene_info)), gene_info$bin)
n_genes_in_window <- sapply(idx_by_bin, length)
#per ogni bin, conta quanti geni ci sono falling!
# 0  1  2  3  4  5 
#86 85 97 88 93 89 

theta_by_bin <- gene_info %>%
  distinct(bin, theta_bin) %>%
  mutate(bin = as.integer(bin)) %>%
  arrange(bin)

##### 6) Mean logTPM per bin per sample

#Compute mean expression per bin per sample
y_bin_mat <- sapply(idx_by_bin, function(idx) {
  colMeans(expr_mat2[idx, , drop=FALSE], na.rm=TRUE)
})
y_bin_mat <- t(y_bin_mat)  # rows=bins, cols=samples
bins <- as.integer(names(idx_by_bin))

bin_expr <- data.frame(
  bin       = rep(bins, times = ncol(y_bin_mat)),
  sample_id = rep(colnames(y_bin_mat), each = length(bins)),
  y         = as.vector(y_bin_mat)
) %>%
  left_join(theta_by_bin, by="bin") %>%
  mutate(n_genes = rep(as.integer(n_genes_in_window), times=ncol(y_bin_mat)))

## 7) Fit circular model per sample: full model only
fit_one_sample <- function(df, use_weights=TRUE) {
  w <- if (use_weights) df$n_genes else NULL
  
  fit0    <- lm(y ~ 1, data=df, weights=w)
  fitFull <- lm(y ~ cos(theta_bin) + sin(theta_bin), data=df, weights=w)
  
  p_full <- anova(fit0, fitFull)$`Pr(>F)`[2]
  
  coefs <- coef(summary(fitFull))
  alpha <- coefs["(Intercept)", "Estimate"]
  beta  <- coefs["cos(theta_bin)", "Estimate"]
  gamma <- coefs["sin(theta_bin)", "Estimate"]
  
  # amplitude/phase representation:
  # y(theta) = alpha + A cos(theta - phi)
  A     <- sqrt(beta^2 + gamma^2)
  phi   <- atan2(gamma, beta)              # [-pi, pi]
  delta <- 2*A                              # naive: max-min in log space
  
  theta_max <- (phi %% (2*pi))             # where cos(theta-phi) is max
  theta_min <- (theta_max + pi) %% (2*pi)
  
  tibble(alpha, beta, gamma, A, phi, delta, theta_max, theta_min, p_full)
}

results <- bin_expr %>%
  group_by(sample_id) %>%
  group_modify(~ fit_one_sample(.x, use_weights=TRUE)) %>%
  ungroup() %>%
  mutate(q_full = p.adjust(p_full, method="BH")) %>%
  as_tibble()

sig_q <- !is.na(results$q_full) & results$q_full < 0.05

## 8) Quick diagnostics (A and beta/gamma cloud)
col_q_fun <- scales::col_numeric(palette=c("red","blue"), domain=c(0,1), na.color="grey80")
pt_col <- col_q_fun(pmin(pmax(results$q_full, 0), 1))

hist(results$A, breaks=50, main="Amplitude A (all samples)", xlab="A",
     col="grey90", border="grey60")
rug(results$A, col="grey60")
#rug(results$A[sig_p], col="orange", lwd=2)
rug(results$A[sig_q], col="red", lwd=2)
legend("topright",
       legend=c("All","q_full<0.05"),
       col=c("grey60","red"), lwd=c(1,2), bty="n")

plot(results$beta, results$gamma,
     xlab="beta (cos)", ylab="gamma (sin)",
     main="beta vs gamma (colored by q_full)",
     pch=16, col=pt_col, cex=ifelse(sig_q, 1.2, 0.7))
abline(h=0, v=0, lty=3)
points(results$beta[sig_q], results$gamma[sig_q],
       pch=21, bg=pt_col[sig_q], col="black", cex=1.25)

## 9) Merge metadata
if (any(names(meta_df) == "")) names(meta_df)[names(meta_df) == ""] <- "unknown_id_col"

find_best_id_col <- function(meta_df, sample_ids) {
  cols <- names(meta_df)
  scores <- sapply(cols, function(cc) sum(as.character(meta_df[[cc]]) %in% sample_ids, na.rm=TRUE))
  cols[which.max(scores)]
}
best_id_col <- find_best_id_col(meta_df, results$sample_id)
cat("Best metadata ID column:", best_id_col, "\n")

meta2 <- meta_df %>% mutate(sample_id = as.character(.data[[best_id_col]]))
merged_results <- results %>% left_join(meta2, by="sample_id")
