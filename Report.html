---
title: "Report Advanced Genomics"
author: "Joel Frayle Moreno- Francesco Mazza"
date: "2026-02-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Project number 5: DNA replication introduces copy number variations that are detectable in RNA-seq

We have to install and run the required packages:

```{r packages, echo=FALSE}
#install.packages('lubridate')
pkgs <- c("dplyr","data.table","stringr","scales","tibble")
for (p in pkgs) if (!requireNamespace(p, quietly=TRUE)) install.packages(p)
library(dplyr); library(data.table); library(stringr); library(scales); library(tibble)
```

## FILE HANDLING 

First we read the datasets and then we explore them. 
expr_df is a collection of gene expression data for E. Coli generated through single cell RNA-seq analysis, and have been already normalized with logarithmic function; each colname represents the experiments, and the rownames represent the genes_identifier;
meta_df instead contains all the metadata related to each sample;


```{r file reading }

expr_df <- read.csv("log_tpm.csv", check.names = FALSE)  # first col = gene_id
meta_df <- read.csv("sample_table.csv", check.names = FALSE)
colnames(expr_df)[1:10]
colnames(meta_df)[1:10]
```

## Mapping
We retrieve the information from NCBI that give us the Genes, and the position in a linear sequence. This is going to help us later to set the position of each one of the genes in our dataset.

```{r file reading }
gff_url  <- "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gz"
gff_file <- "GCF_000005845.2_ASM584v2_genomic.gff.gz"
if (!file.exists(gff_file)) download.file(gff_url, gff_file, mode="wb")
gff <- fread(gff_file, sep="\t", header=FALSE, quote="", comment.char="#", fill=TRUE) #fread help us to manage the information from the NCBI File
setnames(gff, c("seqid","source","type","start","end","score","strand","phase","attr")) #We set some known names to the columns to manage more easy the 
table(gff$type) #We make some expoloration of the data in gff
```

## Extraction usefull information:
  we subset from gff, and we keep only the information for our specific case: gene_id, start and end position of each gene;
  as we need a circular chromosome, we need to compute the specific position; we set "pos" as the average of the start and end positions of each gene; 
  then we will approximate the position of each gene to these "pos" values.

```{r file reading }
gff <- gff[type == "gene"] #We remain just with the gene information
gff[, gene_id := sub(".*locus_tag=([^;]+).*", "\\1", attr)] #We extract from the NCBI attr the identificator of the gene that correspond to the name of the gene in our dataset
gff <- gff[, .(gene_id, start, end)]
typeof(gff$start)
gff[, start := as.integer(start)]
gff[, end   := as.integer(end)]    #We extract the positions of the gene
typeof(gff$start)
L <- max(gff$end, na.rm=TRUE) 
#Sets L to the maximum end coordinate on the main chromosome: 
#your estimate of the genome length (useful for building circular coordinates later). 
#L should be approximately the chromosome length (e.g., ~4.6e6 for E. coli K12).
gene_coords <- gff[grepl("^b\\d{4}$", gene_id),
                          .(gene_id, start, end, pos=(start+end)/2)]
gene_coords <- unique(gene_coords, by="gene_id")
```

## Map expression matrix to genes with coords

We have to make some sanity checks as looking if we have in our dataset one gene more than once. At the end of this block we have "gene_info" with the position, and "expr_mat2" with the expression organized to match the order in "gene_info"

```{r Map expression matrix to genes with coords }
expr_gene_id <- expr_df[[1]] #Expression values themselves have no genomic meaning unless you know which gene each row corresponds to. So we extract the genes id of our dataset.
#This vector becomes the backbone for joining expression ↔ coordinates
anyDuplicated(expr_gene_id) #In our sanity check we have not repeated genes.
#“take genes in expression order, then attach coordinates if available.”
#We create then "gene_info", that contains the genes of our dataset with its respective position.
gene_info <- tibble(gene_id = expr_gene_id) %>%
  left_join(as.data.frame(gene_coords) %>% mutate(gene_id=as.character(gene_id)),
            by="gene_id")


expr_mat <- as.matrix(expr_df[, -1]) #We transform our data into a matrix to apply it in the linear model.
rownames(expr_mat) <- expr_df[[1]]
storage.mode(expr_mat) <- "numeric"
expr_mat2 <- expr_mat[gene_info$gene_id, , drop=FALSE] #We organize our matrix to keep only rows corresponding to genes with coordinates, reorders it to match exactly the order of gene_info.
```
  
## Bin definition
as suggested by the assignment, we divided the circular genome into fixed-size windows of size 100 kb;
  each window is a bin; 
   We have 46 bins, according to the total size of the Coli Genome;
  we then assign each gene to a bin based on its genomic position;
for each bin, we computed a single angular coordinate (theta);
We modeled expression as a sinusoid over the genome.  
  y = α + β cos(θ) + γ sin(θ)
  
```{r file reading }
window_size <- 100000
#E. coli genome ≈ 4.6 Mb → ~46 bins This is a tradeoff:
   #Smaller bins → noisier but higher resolution
   #Larger bins → smoother but may wash out signal
#check
L / window_size    #46.41628
gene_info <- gene_info %>%
  mutate(
    pos_mod   = pos %% L,
    bin       = floor(pos_mod / window_size),
    bin_mid   = ((bin + 0.5) * window_size) %% L,
    theta_bin = 2*pi*bin_mid/L
  )
#y = α + β cos(θ) + γ sin(θ)

idx_by_bin <- split(seq_len(nrow(gene_info)), gene_info$bin)
n_genes_in_window <- sapply(idx_by_bin, length)
# this counts how many genes are in each bin;
# 0  1  2  3  4  5 
#86 85 97 88 93 89 

theta_by_bin <- gene_info %>%
  distinct(bin, theta_bin) %>%
  mutate(bin = as.integer(bin)) %>%
  arrange(bin)
```
  
  
## Mean logTPM per bin per sample

Now we have to aggregate the gene expression into bin expression. So at the end of this step we will have a long format with the bin, the sample, the mean expression, the position in angular coordinate and the number of genes in each window. In this way, if necessary, we can easily apply a weighting.
```{r Bin Expression}
y_bin_mat <- sapply(idx_by_bin, function(idx) {
  colMeans(expr_mat2[idx, , drop=FALSE], na.rm=TRUE)
}) #Here we build our dataset with the average expression for each bin. 
y_bin_mat <- t(y_bin_mat)  # And as we want to mantain the order we use the transpose so we have in the columns the experiments and in the lines the bin.
bins <- as.integer(names(idx_by_bin)) #Its easier to use the bins as an integer in the future

bin_expr <- data.frame(
  bin       = rep(bins, times = ncol(y_bin_mat)),
  sample_id = rep(colnames(y_bin_mat), each = length(bins)),
  y         = as.vector(y_bin_mat)
) %>%
  left_join(theta_by_bin, by="bin") %>%
  mutate(n_genes = rep(as.integer(n_genes_in_window), times=ncol(y_bin_mat))) #Here we have our output for the model. With the long format required

head(bin_expr)
```


```
## Fit circular model per sample: full model only
For each sample, we:
  -fit a null model (flat expression along the genome)
  -fit a circular (sinusoidal) model
Test whether the sinusoid explains significantly more variance
Extract biologically meaningful quantities:
mean level, amplitude, phase (where the peak is), naive CNV metric
  -Correct p-values across samples
  
```{r cars}
  fit_one_sample <- function(df, use_weights=TRUE) {
  w <- if (use_weights) df$n_genes else NULL
  
  fit0    <- lm(y ~ 1, data=df, weights=w)
  fitFull <- lm(y ~ cos(theta_bin) + sin(theta_bin), data=df, weights=w)
  
  p_full <- anova(fit0, fitFull)$`Pr(>F)`[2]
  
  coefs <- coef(summary(fitFull))
  alpha <- coefs["(Intercept)", "Estimate"]
  beta  <- coefs["cos(theta_bin)", "Estimate"]
  gamma <- coefs["sin(theta_bin)", "Estimate"]
  
  # amplitude/phase representation:
  # y(theta) = alpha + A cos(theta - phi)
  A     <- sqrt(beta^2 + gamma^2)
  phi   <- atan2(gamma, beta)              # [-pi, pi]
  delta <- 2*A                              # naive: max-min in log space
  
  theta_max <- (phi %% (2*pi))             # where cos(theta-phi) is max
  theta_min <- (theta_max + pi) %% (2*pi)
  
  tibble(alpha, beta, gamma, A, phi, delta, theta_max, theta_min, p_full)
}

results <- bin_expr %>%
  group_by(sample_id) %>%
  group_modify(~ fit_one_sample(.x, use_weights=TRUE)) %>%
  ungroup() %>%
  mutate(q_full = p.adjust(p_full, method="BH")) %>%
  as_tibble()

sig_q <- !is.na(results$q_full) & results$q_full < 0.05
```


## 8) Quick diagnostics (A and beta/gamma cloud)

col_q_fun <- scales::col_numeric(palette=c("red","blue"), domain=c(0,1), na.color="grey80")
pt_col <- col_q_fun(pmin(pmax(results$q_full, 0), 1))

hist(results$A, breaks=50, main="Amplitude A (all samples)", xlab="A",
     col="grey90", border="grey60")
rug(results$A, col="grey60")
#rug(results$A[sig_p], col="orange", lwd=2)
rug(results$A[sig_q], col="red", lwd=2)
legend("topright",
       legend=c("All","q_full<0.05"),
       col=c("grey60","red"), lwd=c(1,2), bty="n")

plot(results$beta, results$gamma,
     xlab="beta (cos)", ylab="gamma (sin)",
     main="beta vs gamma (colored by q_full)",
     pch=16, col=pt_col, cex=ifelse(sig_q, 1.2, 0.7))
abline(h=0, v=0, lty=3)
points(results$beta[sig_q], results$gamma[sig_q],
       pch=21, bg=pt_col[sig_q], col="black", cex=1.25)

## 9) Merge metadata
if (any(names(meta_df) == "")) names(meta_df)[names(meta_df) == ""] <- "unknown_id_col"

find_best_id_col <- function(meta_df, sample_ids) {
  cols <- names(meta_df)
  scores <- sapply(cols, function(cc) sum(as.character(meta_df[[cc]]) %in% sample_ids, na.rm=TRUE))
  cols[which.max(scores)]
}
best_id_col <- find_best_id_col(meta_df, results$sample_id)
cat("Best metadata ID column:", best_id_col, "\n")

meta2 <- meta_df %>% mutate(sample_id = as.character(.data[[best_id_col]]))
merged_results <- results %>% left_join(meta2, by="sample_id")
