---
title: "Report Advanced Genomics"
author: "Joel Frayle Moreno- Francesco Mazza"
date: "2026-02-11"
output:
  html_document:
    theme: journal
    toc: true
    toc_float: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project number 5: DNA replication introduces copy number variations that are detectable in RNA-seq

We load the packages used throughout the analysis for data manipulation (dplyr, data.table), string handling (stringr), scaling utilities (scales), and tidy outputs (tibble).

```{r packages}
#install.packages('lubridate')
pkgs <- c("dplyr","data.table","stringr","scales","tibble")
for (p in pkgs) if (!requireNamespace(p, quietly=TRUE)) install.packages(p)
library(dplyr); library(data.table); library(stringr); library(scales); library(tibble)
```

## File Handling 

We first load a gene-by-sample expression matrix in logTPM scale, where the first column contains gene identifiers and the remaining columns correspond to samples, and a metadata table with sample-level annotations.


```{r file reading }

expr_df <- read.csv("log_tpm.csv", check.names = FALSE)  # first col = gene_id
meta_df <- read.csv("sample_table.csv", check.names = FALSE)
colnames(expr_df)[1:10]
colnames(meta_df)[1:10]
```

## Mapping
We download the E. coli genome annotation (GFF) from NCBI to obtain genomic coordinates for each gene. These coordinates allow us to map expression measurements onto positions along the chromosome.

```{r mapping }
gff_url  <- "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gz"
gff_file <- "GCF_000005845.2_ASM584v2_genomic.gff.gz"
if (!file.exists(gff_file)) download.file(gff_url, gff_file, mode="wb")
gff <- fread(gff_file, sep="\t", header=FALSE, quote="", comment.char="#", fill=TRUE) #fread help us to manage the information from the NCBI File
setnames(gff, c("seqid","source","type","start","end","score","strand","phase","attr")) #We set some known names to the columns to manage more easy the
genes_main <- copy(gff)
table(gff$type) #We make some expoloration of the data in gff
```

## Extraction usefull information:
In this step we transform the raw NCBI GFF annotation into a clean gene-coordinate table that can be joined with the expression matrix. We first restrict the annotation to features of type gene and extract the locus_tag from the attribute field (attr) to obtain a gene identifier compatible with our dataset. Because the GFF may contain multiple sequences (e.g., chromosome and plasmids), we identify the main chromosome as the seqid with the largest coordinate span and store it in genes_main for downstream origin (oriC) detection. We then keep only the essential columns (gene_id, start, end), enforce integer coordinates, and estimate the chromosome length as $L=\max(end)$. Finally, each gene is represented by a single position $pos=(start+end)/2$ (midpoint), which provides a unique coordinate per gene for subsequent binning and circular mapping.

```{r obtaining coordinates}
gff <- gff[type == "gene"] #We remain just with the gene information
gff[, gene_id := sub(".*locus_tag=([^;]+).*", "\\1", attr)] #We extract from the NCBI attr the identificator of the gene that correspond to the name of the gene in our dataset
seq_spans <- gff[, .(span = max(end, na.rm=TRUE) - min(start, na.rm=TRUE)), by=seqid]
main_seqid <- seq_spans[which.max(span), seqid]
genes_main <- gff[seqid == main_seqid]
gff <- gff[, .(gene_id, start, end)]
gff[, start := as.integer(start)]
gff[, end   := as.integer(end)]    #We extract the positions of the gene
typeof(gff$start)

L <- max(gff$end, na.rm=TRUE) 
#Sets L to the maximum end coordinate on the main chromosome: 
#your estimate of the genome length (useful for building circular coordinates later). 
#L should be approximately the chromosome length (e.g., ~4.6e6 for E. coli K12).
gene_coords <- gff[grepl("^b\\d{4}$", gene_id),
                          .(gene_id, start, end, pos=(start+end)/2)]
gene_coords <- unique(gene_coords, by="gene_id")
head(gene_coords)
```


## Map expression matrix to genes with coords

At this stage, we align the expression matrix with the genomic coordinate table using a common gene identifier. As a basic integrity check, we confirm that gene IDs in the expression input are not duplicated, since repeated identifiers would break the one-to-one mapping between expression rows and genomic positions. We then build gene_info by joining the expression gene list with gene_coords, yielding a per-gene table that includes genomic coordinates (and later-derived quantities such as bin and angle). In parallel, we convert the expression values into a numeric matrix (expr_mat) and reorder/subset it to produce expr_mat2, ensuring that its row order matches exactly the order of gene_info. This guarantees that downstream binning and circular modeling are performed on expression values consistently matched to the correct genomic locations.

```{r Map expression matrix to genes with coords }
expr_gene_id <- expr_df[[1]] #Expression values themselves have no genomic meaning unless you know which gene each row corresponds to. So we extract the genes id of our dataset.
#This vector becomes the backbone for joining expression ↔ coordinates
anyDuplicated(expr_gene_id) #In our sanity check we have not repeated genes.
#“take genes in expression order, then attach coordinates if available.”
#We create then "gene_info", that contains the genes of our dataset with its respective position.
gene_info <- tibble(gene_id = expr_gene_id) %>%
  left_join(as.data.frame(gene_coords) %>% mutate(gene_id=as.character(gene_id)),
            by="gene_id")


expr_mat <- as.matrix(expr_df[, -1]) #We transform our data into a matrix to apply it in the linear model.
rownames(expr_mat) <- expr_df[[1]]
storage.mode(expr_mat) <- "numeric"
expr_mat2 <- expr_mat[gene_info$gene_id, , drop=FALSE] #We organize our matrix to keep only rows corresponding to genes with coordinates, reorders it to match exactly the order of gene_info.
head(expr_mat2[, 1:6, drop=FALSE])
```

## Genes grouped by Bins
## Genes grouped by bins

To represent the circular chromosome at a coarser (and less noisy) resolution, we partitioned the genome into fixed windows of 100 kb (“bins”). Each gene was assigned to a bin using its genomic midpoint, and because the chromosome is circular we used the wrapped coordinate $pos\_{mod} = pos \bmod L$ to keep positions inside $[0, L)$.

For each bin we defined a single representative angular coordinate $\theta$ using the bin midpoint. This midpoint was mapped onto $[0,2\pi)$ as:
$$\theta = \frac{2\pi \cdot \text{bin\_mid}}{L}.$$

This bin-level angle is the input for the downstream circular regression model,
$$y = \alpha + \beta\cos(\theta) + \gamma\sin(\theta),$$
where $y$ is the mean log-expression per bin. We also tracked the number of genes per bin ($n\_{genes}$), which can later be used as regression weights to account for unequal gene counts across windows.
  
```{r bin definition }
window_size <- 100000
#E. coli genome ≈ 4.6 Mb → ~46 bins This is a tradeoff:
   #Smaller bins → noisier but higher resolution
   #Larger bins → smoother but may wash out signal
L / window_size    #46.41628
gene_info <- gene_info %>%
  mutate(
    pos_mod   = pos %% L,
    bin       = floor(pos_mod / window_size),
    bin_mid   = ((bin + 0.5) * window_size) %% L,
    theta_bin = 2*pi*bin_mid/L
  )
#y = α + β cos(θ) + γ sin(θ)

idx_by_bin <- split(seq_len(nrow(gene_info)), gene_info$bin)
n_genes_in_window <- sapply(idx_by_bin, length)
# this counts how many genes are in each bin;
# 0  1  2  3  4  5 
#86 85 97 88 93 89 

theta_by_bin <- gene_info %>%
  distinct(bin, theta_bin) %>%
  mutate(bin = as.integer(bin)) %>%
  arrange(bin)
```

## Mean logTPM per bin per sample

To fit the circular model, we first aggregated gene-level expression into bin-level expression. For each sample and each genomic bin, we computed the mean of the logTPM values across all genes assigned to that bin:
$$y_{b,s}=\frac{1}{|G_b|}\sum_{g\in G_b} y_{g,s},$$
where $G_b$ is the set of genes in bin $b$. Because the expression matrix is already in log scale, averaging within bins provides a stable summary of the bin’s typical expression level.

We then reshaped the bin-by-sample matrix into a long-format table with one row per $(bin,\ sample)$ pair, and we attached: (i) the bin’s angular coordinate $\theta_{bin}$ (from the bin midpoint) and (ii) the number of genes in the bin $n_{genes}=|G_b|$. This final table (`bin_expr`) is the direct input for the per-sample circular regression, and $n_{genes}$ can be used as a weight to account for bins containing different numbers of genes.
```{r Bin Expression}
y_bin_mat <- sapply(idx_by_bin, function(idx) {
  colMeans(expr_mat2[idx, , drop=FALSE], na.rm=TRUE)
}) #Here we build our dataset with the average expression for each bin. 
y_bin_mat <- t(y_bin_mat)  # And as we want to mantain the order we use the transpose so we have in the columns the experiments and in the lines the bin.
bins <- as.integer(names(idx_by_bin)) #Its easier to use the bins as an integer in the future

bin_expr <- data.frame(
  bin       = rep(bins, times = ncol(y_bin_mat)),
  sample_id = rep(colnames(y_bin_mat), each = length(bins)),
  y         = as.vector(y_bin_mat)
) %>%
  left_join(theta_by_bin, by="bin") %>%
  mutate(n_genes = rep(as.integer(n_genes_in_window), times=ncol(y_bin_mat))) #Here we have our output for the model. With the long format required

head(bin_expr)
```

## Fit circular model per sample
For each sample, we fit a null model (fit0) that assumes constant expression across the genome (y=α), we will use this later to compare if using circular model (y = α + β cos(θ) + γ sin(θ)) improves it significantly the fit.

We parametrized the circular model using sine and cosine basis functions, allowing the sinusoidal pattern to be estimated within a linear regression framework. This avoids nonlinear optimization ($y = \alpha + A *Cos(\theta-\phi) $) over amplitude and phase parameters.

The non linear model starts by representing the bin as follows:
$$A(\cos(\theta-\phi))=A\cos(\theta)\cos(\phi)+A\sin(\theta)\sin(\phi)$$
We defined:S
$$\beta = A\cos{\phi}$$
$$\gamma=A\sin(\phi)$$
With this transformation we represent the same model with a different parameterization. From the previous analysis we can set as useful information that:
$$A=\sqrt{\beta^2+\gamma^2}$$
That give us the amplitude And:
$$\phi=\operatorname{atan2}(\gamma, \beta)$$
That give us the phase, so the position in the circular chromosome in dependence of $\gamma$ and $\beta$.
We at this point can use also a theoretical treatment that define the phase duration as C= DNA synthesis phase and D= predivisional phase. The doubling time is $\tau = \frac{2}{growthrate}$ and the position of a locus is $n_a= 2^{\frac{p_aC+D}{\tau}}$ where $n_a$ is the copy number of locus $a$ positioned at a distance $p_a$ from the terminus of the chromosome. Due to this we can arrive that: $$log_2\frac{n_{ori}}{n_{ter}}=\frac{C}{\tau}=\frac{C\mu}{ln(2)}$$

In our case we can say that, if expression is proportional to copy number, then in $log_2$ space the difference between maximal and minimal expression across the chromosome corresponds to:
$$y_{max}-y_{min}=2A=\delta$$
Thus, the fitted amplitude A provides a quantitative estimate of the replication-associated expression gradient.
We can retrive the position due to the fact that we have $\phi$, where the expression is maximum and minimum in radiants;
to apply the model to all the samples, we used the fit_one_sample function that we've just created. This function operates on one sample's binned data, so in the "results" variable for each sample, there are all the parameters of the fitted model explained above.  
In order to evaluate if there is statistical evidence to reject the null model "fit0", we used an anova F test to compute p value (p_full), then corrected with BH method for multiple testing correction (q_full)
```{r Model}
fit_one_sample <- function(df, use_weights=TRUE) {
  w <- if (use_weights) df$n_genes else NULL
  
  fit0    <- lm(y ~ 1, data=df, weights=w)
  fitFull <- lm(y ~ cos(theta_bin) + sin(theta_bin), data=df, weights=w)
  
  # Reduced models (for later comparison)
  fitCos <- lm(y ~ cos(theta_bin), data=df, weights=w)
  fitSin <- lm(y ~ sin(theta_bin), data=df, weights=w)
  
  p_full <- anova(fit0, fitFull)$`Pr(>F)`[2]
  p_cos  <- anova(fit0, fitCos )$`Pr(>F)`[2]
  p_sin  <- anova(fit0, fitSin )$`Pr(>F)`[2]
  
  coefs <- coef(summary(fitFull))
  alpha <- coefs["(Intercept)", "Estimate"]
  beta  <- coefs["cos(theta_bin)", "Estimate"]
  gamma <- coefs["sin(theta_bin)", "Estimate"]
  
  # amplitude/phase representation:
  # y(theta) = alpha + A cos(theta - phi)
  A     <- sqrt(beta^2 + gamma^2)
  phi   <- atan2(gamma, beta)              # [-pi, pi]
  delta <- 2*A                              # naive: max-min in log space
  
  theta_max <- (phi %% (2*pi))             # where cos(theta-phi) is max
  theta_min <- (theta_max + pi) %% (2*pi)
  
  tibble(alpha, beta, gamma, A, phi, delta, theta_max, theta_min, p_full, p_cos, p_sin)
}

results <- bin_expr %>%
  group_by(sample_id) %>%
  group_modify(~ fit_one_sample(.x, use_weights=TRUE)) %>%
  ungroup() %>%
  mutate(
    q_full = p.adjust(p_full, method="BH"),
    q_cos  = p.adjust(p_cos,  method="BH"),
    q_sin  = p.adjust(p_sin,  method="BH")
  ) %>%
  as_tibble()

sig_q <- !is.na(results$q_full) & results$q_full < 0.05
head(results)
```
## Visual Data exploration
The histogram shows the distribution of amplitude values across all samples. Most amplitudes cluster at low values, and the distribution is clearly right-skewed, with a long tail toward larger amplitudes. The rug marks indicate where significant fits (`q_full < 0.05`) fall along the x-axis: they are sparse at very low amplitudes and become increasingly frequent as amplitude increases, concentrating mainly in the upper part of the distribution.

This scatter plot shows the fitted $\beta$ (cosine component) against $\gamma$ (sine component) across samples, with points colored by `q_full`. The cloud is densest near the origin, indicating that most samples have small estimated coefficients. As expected, the most significant fits concentrate away from (0,0), while points near the origin are predominantly non-significant. The distribution is not isotropic: the sample cloud is elongated along a negative diagonal, suggesting that $\beta$ and $\gamma$ may not be independent in practice and tend to co-vary with opposite signs in many samples.

How are these significant values distributed? In the $(\beta,\gamma)$ plane, significant samples are primarily enriched at larger distances from the origin (equivalently, larger $A$), indicating that significance largely tracks effect size. In our data, the median $A$ increases from 0.0859 in non-significant samples to 0.214 in significant samples (`q_full < 0.05`; Wilcoxon p-value $= 5.89\times10^{-38}$). To assess whether there is also a preferred direction (i.e., a consistent peak location across samples), we examine the angular distribution (`phi`) among significant samples; the resulting histogram shows clear clustering rather than a uniform spread, suggesting that many significant samples share similar peak directions.

What happens if the models account only for the cosine or only for the sine term? The reduced models typically retain significance only for samples whose signal is sufficiently aligned with that single basis term. In our dataset, the full model identifies 95 significant samples, whereas the cosine-only and sine-only models identify 24 and 39, respectively. Importantly, 37 samples are significant under the full model but not under either reduced model, consistent with signals that require both sine and cosine terms (i.e., peak directions not aligned with a single basis). Conversely, only 5 samples are significant under the sine-only model but not under the full model, which is consistent with borderline cases where the 1-df reduced model can be slightly more powerful than the 2-df full model.

What does the estimated parameter mean? The pair $(\beta,\gamma)$ jointly encodes magnitude and direction: the distance to the origin reflects effect size (strength of the fitted pattern), while the angle (`phi`) reflects where along the circle the maximum/minimum occurs. Therefore, points farther from (0,0) correspond to stronger fitted patterns, while different quadrants/angles correspond to different peak positions.

Do you think one can derive a quantitative relationship of the parameter from the model and the growth rate? Under the replication-driven assumptions, larger effect sizes (e.g., $A$ or $2A$) should tend to be associated with higher growth rate $\mu$.
}
Overall, these comparisons support using q_full as the primary significance criterion in the remainder of the analysis. The full model is phase-invariant (it captures signal regardless of whether it aligns with the cosine or sine basis) and therefore detects substantially more significant samples than either reduced model (95 vs 24/39). The presence of many ‘full-only’ cases (37 samples significant only under q_full) indicates that restricting to a single basis term would miss a large fraction of signals whose peak direction is not aligned with that term. While a small number of borderline cases can be recovered by a 1-df reduced model (5 samples significant only under q_sin), the overall gain in sensitivity and robustness makes q_full the most appropriate and conservative choice for downstream analyses.
```{r Plot, echo=FALSE}
col_q_fun <- scales::col_numeric(palette=c("red","blue"), domain=c(0,1), na.color="grey80")
pt_col <- col_q_fun(pmin(pmax(results$q_full, 0), 1))


hist(results$A, breaks=50, main="Amplitude A (all samples)", xlab="A",
       col="grey90", border="grey60")
rug(results$A, col="grey60")
rug(results$A[sig_q], col="red", lwd=2)
legend("topright",
         legend=c("All","q_full<0.05"),
         col=c("grey60","red"), lwd=c(1,2), bty="n")

plot(results$beta, results$gamma,
       xlab="beta (cos)", ylab="gamma (sin)",
       main="beta vs gamma (colored by q_full)",
       pch=16, col=pt_col, cex=ifelse(sig_q, 1.2, 0.7))
  abline(h=0, v=0, lty=3)
  points(results$beta[sig_q], results$gamma[sig_q],
         pch=21, bg=pt_col[sig_q], col="black", cex=1.25)

sig_full <- !is.na(results$q_full) & results$q_full < 0.05
sig_cos  <- !is.na(results$q_cos)  & results$q_cos  < 0.05
sig_sin  <- !is.na(results$q_sin)  & results$q_sin  < 0.05

# Effect size enrichment: significant samples have larger A
w_test <- wilcox.test(results$A ~ sig_full)

A_summary <- tibble(
  group = c("non-significant (q_full >= 0.05)", "significant (q_full < 0.05)"),
  median_A = c(median(results$A[!sig_full], na.rm=TRUE),
               median(results$A[sig_full],  na.rm=TRUE))
)

wilcox_summary <- tibble(
  test = "Wilcoxon rank-sum test: A ~ (q_full < 0.05)",
  p_value = w_test$p.value
)

# Full vs reduced models: counts and overlap structure
overlap_summary <- tibble(
  category = c("Significant (full model): q_full < 0.05",
               "Significant (cos-only): q_cos < 0.05",
               "Significant (sin-only): q_sin < 0.05",
               "Full-only: q_full < 0.05 AND q_cos >= 0.05 AND q_sin >= 0.05",
               "Sin-only not full: q_sin < 0.05 AND q_full >= 0.05"),
  n = c(sum(sig_full, na.rm=TRUE),
        sum(sig_cos,  na.rm=TRUE),
        sum(sig_sin,  na.rm=TRUE),
        sum(sig_full & !sig_cos & !sig_sin, na.rm=TRUE),
        sum(sig_sin & !sig_full, na.rm=TRUE))
)

# Compact overlap tables, but labeled so they are self-explanatory when printed
tab_full_cos <- table(`Full significant (q_full<0.05)` = sig_full,
                      `Cos-only significant (q_cos<0.05)` = sig_cos)

tab_full_sin <- table(`Full significant (q_full<0.05)` = sig_full,
                      `Sin-only significant (q_sin<0.05)` = sig_sin)

# Directionality: wrap phi to [0, 2pi) to avoid the ±pi boundary split
phi_02pi <- (results$phi %% (2*pi))

# Print outputs (labeled, so no guessing)
A_summary
wilcox_summary
overlap_summary
tab_full_cos
tab_full_sin

hist(phi_02pi[sig_full], breaks=30,
     main="phi distribution (significant only, wrapped to [0, 2pi))",
     xlab="phi (radians)")
```

## Merge metadata
```{r Merge}

i <- which(names(meta_df) == "")[1]
names(meta_df)[i] <- "sample_id"

merged_results <- dplyr::left_join(
  results,
  dplyr::distinct(meta_df, sample_id, .keep_all = TRUE),
  by = "sample_id"
)

```

## Identification of oriC position

To anchor the circular expression model to a biologically meaningful reference point, we determined the genomic position of the replication origin (oriC). 
  In *E. coli*, the dnaA gene is located immediately adjacent to oriC and was therefore used as a proxy for the origin position. 
  The dnaA locus was identified from the genome annotation, and its midpoint was computed as:

$$ori_{pos} = \frac{\text{start}_{\text{dnaA}} + \text{end}_{\text{dnaA}}}{2}.$$

This genomic coordinate was then mapped onto the circular genome using:

$$ \theta_{\text{ori}} = \frac{2\pi \cdot (ori_{pos} \equiv L)}{L}$$

where \( L \) is the chromosome length. 
  The resulting angular coordinate defines the position of oriC within the circular regression framework and enables computation of the origin–terminus expression contrast.

  
```{r theta Ori}
  ori_row <- genes_main[grepl("(^|;)gene=dnaA(;|$)|(^|;)Name=dnaA(;|$)", attr)]
if (nrow(ori_row) == 0) {
  print(head(genes_main[grepl("dnaA", attr)]$attr, 10))
  stop("dnaA not found with gene=/Name=. Inspect attr above and adjust grepl().")
}
ori_pos <- (ori_row$start[1] + ori_row$end[1]) / 2
theta_ori <- (2*pi*(ori_pos %% L))/L
cat("theta_ori (radians):", theta_ori, "\n")
```

## Peak angles and directionality check

At this stage we have already identified, for each sample, the peak location of the fitted replication-related pattern ($\theta_{max}$) and we restrict the analysis to samples with a significant full model ($q_{full} < 0.05$). The key question is whether these peak angles are randomly distributed along the circular chromosome or show a consistent preferred direction relative to the replication origin. The Rayleigh test strongly rejects the hypothesis of a uniform angular distribution, indicating that the peaks are not random but instead concentrate around a specific direction. However, the directed V-tests show that this concentration is not toward our oriC reference angle $\theta_{ori}$, but rather toward the opposite direction $\theta_{ori}+\pi$. In other words, the fitted “peak direction” is systematically shifted by approximately half a chromosome relative to the origin anchor.
This empirical result matters for the downstream quantification of the origin–terminus contrast: it implies that a naive definition based on the fitted maximum/minimum locations (e.g., using $\theta_{max}$ and $\theta_{min}$) would not reliably represent an ori-centered replication gradient in this dataset. Therefore, before proceeding to any technical derivation, these directionality tests motivate an explicit ori-anchored contrast that compares expression at $\theta_{ori}$ versus $\theta_{ori}+\pi$.

```{r Rayleigh and V- Test}

if (!requireNamespace("circular", quietly = TRUE)) install.packages("circular")
if (!requireNamespace("CircStats", quietly = TRUE)) install.packages("CircStats")
library(circular)
library(CircStats)

sig_q <- !is.na(results$q_full) & results$q_full < 0.05 # We use only BH-significant samples from the full model

th <- (results$theta_max[sig_q]) %% (2*pi) # We need to transform the indormation in a circular form.

mu_ori <- (theta_ori) %% (2*pi)
mu_opp <- (mu_ori+pi) %% (2*pi)

ray <- circular::rayleigh.test(circular(th, units = "radians", modulo = "2pi")) #We perform the tests
vt_ori <- CircStats::v0.test(th, mu0 = mu_ori, degree = FALSE)
vt_opp <- CircStats::v0.test(th, mu0 = mu_opp, degree = FALSE)

mu_hat <- atan2(mean(sin(th)), mean(cos(th))) %% (2*pi)
Rbar  <- sqrt(mean(cos(th))^2 + mean(sin(th))^2)

V_ori <- sum(cos(th - mu_ori)); rbar_ori <- V_ori / length(th)
V_opp <- sum(cos(th - mu_opp)); rbar_opp <- V_opp / length(th)

tibble(
  n_sig = length(th),
  theta_ori = mu_ori,
  theta_opp = mu_opp,
  mu_hat = mu_hat,
  Rbar = Rbar,
  rayleigh_p = unname(ray$p.value),
  V_ori = V_ori,
  rbar_ori = rbar_ori,
  p_ori = unname(vt_ori$p.value),
  V_opp = V_opp,
  rbar_opp = rbar_opp,
  p_opp = unname(vt_opp$p.value)
)
```


## Correction step
To obtain a biologically anchored estimate, we redefined the contrast directly on the fitted model as the difference between the predicted expression at the origin and at the antipodal position:
$$\Delta_{ori}=y(\theta_{ori})-y(\theta_{ori}+\pi)= 2(\beta\cos{\theta_{ori}}+\gamma\sin{\theta_{ori}})$$
which preserves the sign (ori higher vs opposite higher) and enforces a consistent ori-based reference across samples.

```{r Delta correction}
results <- results %>%
  mutate(
    delta_ori = 2 * (beta*cos(theta_ori) + gamma*sin(theta_ori)),
    delta_opp = -delta_ori
  )

merged_results <- merged_results %>%
  dplyr::left_join(
    dplyr::select(results, sample_id, delta_ori, delta_opp),
    by = "sample_id"
  )

sig_q <- !is.na(results$q_full) & results$q_full < 0.05

delta_summary <- results %>%
  filter(sig_q) %>%
  summarise(
    n_sig = n(),
    median_delta_naive = median(delta, na.rm=TRUE),     # delta = 2A (max–min)
    median_delta_ori   = median(delta_ori, na.rm=TRUE), # ori-anchored contrast
    cor_naive_vs_ori   = cor(delta, delta_ori, use="complete.obs"),
    prop_delta_ori_pos = mean(delta_ori > 0, na.rm=TRUE),
    prop_delta_ori_neg = mean(delta_ori < 0, na.rm=TRUE)
  )

cat("\n### Delta contrast summary (q_full < 0.05)\n")
delta_summary

cat("\n### Example rows: naive delta (2A) vs corrected delta_ori\n")

results %>%
  dplyr::filter(sig_q) %>%
  dplyr::select(sample_id, q_full, A, delta, delta_ori) %>%
  dplyr::arrange(q_full) %>%
  head(10)
```
## Integration with measured growth rates

To evaluate whether the replication-associated expression gradient scales with bacterial growth, we integrated the growth-rate metadata provided for each sample. Growth rate was taken directly from the metadata column “Growth Rate (1/hr)” and converted to numeric. As indicated in the dataset documentation, samples with growth rate equal to 1 correspond to missing measurements and were excluded from downstream analyses. We further restricted the dataset to samples with finite estimates of the fitted effect size (A), the naive amplitude contrast ($\Delta=2A$), and the ori-anchored contrast ($\Delta_{ori}$). Finally, we defined the subset of statistically supported patterns using the BH-adjusted significance threshold on the full model ($q_{full}<0.05$), which is used in the subsequent association analyses with growth rate.

```{r growth rate}
merged_results2 <- merged_results %>%
  dplyr::mutate(
    growth_rate = as.numeric(`Growth Rate (1/hr)`)
  )

## Keep only samples with measured growth rate (exclude sentinel = 1) and finite contrasts
known <- merged_results2 %>%
  dplyr::filter(
    !is.na(growth_rate),
    growth_rate != 1,
    is.finite(delta_ori),
    is.finite(delta),
    is.finite(A)
  )

## Significant fits (full model BH)
mask_q <- !is.na(known$q_full) & known$q_full < 0.05

## Quick look
known %>%
  dplyr::select(sample_id, growth_rate, q_full, A, delta, delta_ori) %>%
  dplyr::arrange(growth_rate) %>%
  head(10)
```

## Correlation analysis between replication signal and growth rate

Using the samples with measured growth rate (known), we tested whether the replication-associated signal scales with growth by correlating growth rate with (i) the naive amplitude contrast $\Delta=2A$ and (ii) the ori-anchored contrast $\Delta_{ori}$ defined above. Correlations were computed on all samples with growth-rate measurements and on the subset of samples with a significant circular signal ($q<0.05$).

In the left plot, ($\delta=2A$) mainly tells you how strong the wave is in each sample. Red points (significant fits) tend to have larger delta, which just means the wave is clearer. But growth rate does not increase in a clear way as delta increases. In the right plot, delta_ori tells you which side is higher. The positive positive side are the ones higher at the origin side, and the negative are higher on the opposite side.

Most non-significant samples sit near 0 (no clear difference). Significant samples spread away from 0, and many are negative, matching the earlier result that the peak is often opposite to the origin proxy. Therefore we keep using delta_ori, because it measures the specific “origin vs opposite” difference, not just the strength of the wave.

```{r correlation, echo=FALSE}
# Significant subset (BH on the full model)
mask_q <- !is.na(known$q_full) & known$q_full < 0.05

# Correlation table
corr_tab <- tibble(
  set = c("ALL", "ALL", "q_full<0.05", "q_full<0.05"),
  metric = c("delta (=2A)", "delta_ori", "delta (=2A)", "delta_ori"),
  pearson = c(
    cor(known$delta, known$growth_rate, use="complete.obs", method="pearson"),
    cor(known$delta_ori, known$growth_rate, use="complete.obs", method="pearson"),
    cor(known$delta[mask_q], known$growth_rate[mask_q], use="complete.obs", method="pearson"),
    cor(known$delta_ori[mask_q], known$growth_rate[mask_q], use="complete.obs", method="pearson")
  ),
  spearman = c(
    cor(known$delta, known$growth_rate, use="complete.obs", method="spearman"),
    cor(known$delta_ori, known$growth_rate, use="complete.obs", method="spearman"),
    cor(known$delta[mask_q], known$growth_rate[mask_q], use="complete.obs", method="spearman"),
    cor(known$delta_ori[mask_q], known$growth_rate[mask_q], use="complete.obs", method="spearman")
  )
)

corr_tab

# Scatter plots (ALL), colored by q_full (already defined earlier as col_q_fun)
cols <- col_q_fun(pmin(pmax(known$q_full, 0), 1))

par(mfrow=c(1,2))

plot(known$delta, known$growth_rate, pch=16, col=cols,
     xlab="delta (=2A)", ylab="Growth Rate (1/hr)",
     main="delta vs growth rate (colored by q_full)")
abline(h=0, v=0, lty=3)

plot(known$delta_ori, known$growth_rate, pch=16, col=cols,
     xlab="delta_ori", ylab="Growth Rate (1/hr)",
     main="delta_ori vs growth rate (colored by q_full)")
abline(h=0, v=0, lty=3)

par(mfrow=c(1,1))
```

## Cross-validation of predictive models

To quantify how informative the replication-related metrics are about bacterial growth, we framed the problem as a prediction task: given a sample’s replication signal estimated from the circular model, can we predict its measured growth rate $\mu$ (1/hr)? We evaluated simple linear regression models because the project’s theoretical expectation suggests an approximately monotonic relationship between copy-number gradients and growth, and linear models are interpretable and allow a clean comparison between alternative replication metrics.

We compared four model specifications:

- $m_A$: $\mu \sim A$, where $A=\sqrt{\beta^2+\gamma^2}$ is the fitted amplitude (effect size) of the sinusoid.
- $m_\Delta$: $\mu \sim \Delta$, where $\Delta = 2A$ is the naive peak-to-trough contrast of the fitted sinusoid (phase-free).
- $m_{\Delta_{\mathrm{ori}}}$: $\mu \sim \Delta_{\mathrm{ori}}$, where 
  $$\Delta_{\mathrm{ori}} = y(\theta_{\mathrm{ori}})-y(\theta_{\mathrm{ori}}+\pi)=2\big(\beta\cos\theta_{\mathrm{ori}}+\gamma\sin\theta_{\mathrm{ori}}\big)$$
  is the ori-anchored contrast (signed), directly addressing the biological question “origin vs opposite/terminus”.
- $m_{\Delta_{\mathrm{ori}}+A}$: $\mu \sim \Delta_{\mathrm{ori}} + A$, to test whether adding “overall signal strength” ($A$) improves prediction beyond the ori-anchored contrast.

Because $\Delta = 2A$, models $m_A$ and $m_\Delta$ are expected to behave identically (up to rescaling), and are effectively two views of the same phase-free effect-size information.

Then, to estimate out-of-sample performance, we used repeated 5-fold cross-validation (50 repetitions). In each repetition, samples were randomly split into 5 folds; each fold was predicted by a model trained on the other 4 folds, and predictions were pooled across folds to compute performance metrics. We report:

- RMSE: $\sqrt{\frac{1}{n}\sum_i(\mu_i-\hat{\mu}_i)^2}$  
- MAE: $\frac{1}{n}\sum_i|\mu_i-\hat{\mu}_i|$  
- $R^2$: $1-\frac{\sum_i(\mu_i-\hat{\mu}_i)^2}{\sum_i(\mu_i-\bar{\mu})^2}$

We evaluated performance on two datasets: First , all samples with valid growth-rate measurements (excluding the sentinel value $\mu=1$ used for missing growth rates), and the second one sig\_q: the subset with a statistically supported circular signal ($q_{\mathrm{full}}<0.05$).
  In the full dataset, the ori-anchored contrast $\Delta_{\mathrm{ori}}$ provides measurable predictive value (positive $R^2$), whereas phase-free effect-size predictors ($A$ or $\Delta$) perform worse than predicting the mean growth rate (negative $R^2$). This indicates that, once phase is ignored, “how strong the wave is” does not reliably map to growth across heterogeneous conditions; anchoring the contrast to ori carries substantially more growth-relevant information.
  
Restricting to samples with a clear circular replication signal strengthens the relationship: $\Delta_{\mathrm{ori}}$ explains a substantial fraction of out-of-sample variance ($R^2 \approx 0.59$). Adding $A$ slightly worsens performance, suggesting that once the contrast is correctly oriented (ori vs opposite), additional “overall amplitude” does not add independent predictive information and may introduce noise given the small sample size.

These results are consistent with the earlier directionality analysis: in this dataset the fitted peak location is not reliably aligned with $\theta_{\mathrm{ori}}$, so phase-free metrics ($A$ or $\Delta$) are not appropriate proxies for an origin–terminus gradient. In contrast, $\Delta_{\mathrm{ori}}$ directly measures the fitted expression difference between ori and the opposite genomic position, preserving direction and remaining interpretable even when the peak is shifted. Therefore, in the remainder of the analysis we treat $\Delta_{\mathrm{ori}}$ as the primary replication signal when relating the fitted sinusoid to growth rate.

```{r cross_validation}
# datasets
mask_q <- !is.na(known$q_full) & known$q_full < 0.05
datasets <- list(
  ALL = known,
  sig_q = known[mask_q, , drop = FALSE]
)

# models (keep it small and interpretable)
models <- list(
  delta_ori   = growth_rate ~ delta_ori,
  delta       = growth_rate ~ delta,
  A           = growth_rate ~ A,
  delta_ori_A = growth_rate ~ delta_ori + A
)

# repeated 5-fold CV
cv_rep <- function(df, form, k = 5, R = 50, seed = 1) {
  set.seed(seed)
  n <- nrow(df)
  out <- vector("list", R)

  for (r in seq_len(R)) {
    fold <- sample(rep(seq_len(k), length.out = n))
    y <- df$growth_rate
    pred <- rep(NA_real_, n)

    for (f in seq_len(k)) {
      fit <- lm(form, data = df[fold != f, , drop = FALSE])
      pred[fold == f] <- predict(fit, newdata = df[fold == f, , drop = FALSE])
    }

    res <- y - pred
    rmse <- sqrt(mean(res^2, na.rm = TRUE))
    mae  <- mean(abs(res), na.rm = TRUE)
    r2   <- 1 - sum(res^2, na.rm = TRUE) / sum((y - mean(y, na.rm = TRUE))^2, na.rm = TRUE)

    out[[r]] <- tibble(RMSE = rmse, MAE = mae, R2 = r2)
  }

  dplyr::bind_rows(out)
}

# run CV
cv_all <- list()
for (ds in names(datasets)) {
  for (m in names(models)) {
    cv_all[[paste(ds, m, sep = "__")]] <-
      cv_rep(datasets[[ds]], models[[m]]) %>%
      dplyr::mutate(dataset = ds, model = m, n = nrow(datasets[[ds]]))
  }
}
cv_df <- dplyr::bind_rows(cv_all)

# summary table (main deliverable)
cv_summary <- cv_df %>%
  dplyr::group_by(dataset, model, n) %>%
  dplyr::summarise(
    RMSE = mean(RMSE, na.rm = TRUE),
    MAE  = mean(MAE,  na.rm = TRUE),
    R2   = mean(R2,   na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::arrange(dataset, RMSE)

cv_summary

# RMSE distributions (compact visual comparison)
library(ggplot2)
library(dplyr)

cv_df$model <- factor(cv_df$model,
                      levels = c("A","delta","delta_ori","delta_ori_A"))

p <- cv_df %>%
  filter(dataset %in% c("ALL","sig_q")) %>%
  mutate(dataset = ifelse(dataset=="ALL",
                          "ALL samples",
                          "Significant (q < 0.05)")) %>%
  ggplot(aes(x=model, y=RMSE, fill=model)) +
  geom_boxplot(alpha=0.8, outlier.alpha=0.3) +
  facet_wrap(~dataset, scales="free_y") +
  scale_fill_brewer(palette="Blues") +
  theme_minimal(base_size = 13) +
  theme(
    legend.position="none",
    axis.text.x = element_text(angle=45, hjust=1),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = "Model comparison via repeated cross-validation",
    y = "RMSE",
    x = "Model"
  )

print(p)

```

## Final model fitting
Based on the cross-validation results, we retained the simplest and best-performing specification and fitted the final model on the full dataset $growth_rate \sim \Delta_{ori}$.

Across all samples with measured growth rate ($n=353$), $\Delta_{ori}$ shows a clear positive association with growth (slope $=0.660$, $p=9.35\times 10^{-14}$), explaining a modest but non-negligible fraction of variance ($R^2=0.146$). This is expected in a heterogeneous compendium where many factors beyond replication-related gene dosage contribute to growth.

We then fitted the same model on a higher-confidence subset restricted to samples with a statistically significant circular signal ($q_{full}<0.05$; $n=27$). In this subset the relationship strengthens substantially (slope $=0.881$, $p=2.19\times 10^{-7}$), and the model explains roughly two thirds of the observed growth-rate variance ($R^2=0.665$). Overall, these final fits confirm that the ori-anchored replication contrast $\Delta_{ori}$ is an interpretable predictor of growth, and that its explanatory power is highest when the replication-associated sinusoidal signal is clearly detectable in the transcriptome.

```{r final model fitting}
# Final model (ALL samples with growth rate)
fit_all <- lm(growth_rate ~ delta_ori, data = known)

# High-confidence subset (q_full < 0.05)
mask_q <- !is.na(known$q_full) & known$q_full < 0.05
fit_sigq <- lm(growth_rate ~ delta_ori, data = known[mask_q, , drop = FALSE])

summary(fit_all)
summary(fit_sigq)
```
## Out-of-fold predictions and regression diagnostics

As an extra check on the final model ($growth\_rate \sim \Delta_{ori}$), we generated out-of-fold (OOF) predictions with a single 5-fold split (one prediction per sample, always from a model trained without that sample). This complements the repeated CV summary by showing how the errors look, not only how big they are.

The cloud follows the expected upward trend, so $\Delta_{ori}$ carries real signal. However, predictions are pulled toward the average: very low growth tends to be overestimated and very high growth tends to be underestimated. This “regression to the mean” is typical for a simple one-feature linear model.

Residuals are centered around zero with no strong curved pattern, which supports a roughly linear relationship at this resolution. The spread is not perfectly constant and a few points sit far from zero, suggesting remaining variability driven by factors not included in the model (condition-to-condition differences, noise, or other biology beyond replication signal).

Residuals are broadly symmetric but not perfectly tight, consistent with a model that captures a real effect while leaving substantial unexplained variation in the full dataset.

Overall, the diagnostics match what we saw in cross-validation: $\Delta_{ori}$ is a meaningful predictor, but a single linear term cannot fully explain growth across all experimental conditions.

```{r diagnostics}
set.seed(123)

df <- known
k  <- 5

# Assign folds once, produce one OOF prediction per sample
fold_id <- sample(rep(1:k, length.out = nrow(df)))
pred_oof <- rep(NA_real_, nrow(df))

for (f in 1:k) {
  fit <- lm(growth_rate ~ delta_ori, data = df[fold_id != f, , drop=FALSE])
  pred_oof[fold_id == f] <- predict(fit, newdata = df[fold_id == f, , drop=FALSE])
}

resid_oof <- df$growth_rate - pred_oof

rmse_oof <- sqrt(mean(resid_oof^2, na.rm=TRUE))
mae_oof  <- mean(abs(resid_oof), na.rm=TRUE)
r2_oof   <- 1 - sum(resid_oof^2, na.rm=TRUE) / 
  sum((df$growth_rate - mean(df$growth_rate, na.rm=TRUE))^2, na.rm=TRUE)

tibble(
  model = "OOF 5-fold | growth_rate ~ delta_ori",
  RMSE = rmse_oof,
  MAE  = mae_oof,
  R2   = r2_oof
)

# Plots
cols <- col_q_fun(pmin(pmax(df$q_full, 0), 1))

par(mfrow=c(1,3), mar=c(4,4,2,1))

plot(df$growth_rate, pred_oof,
     pch=16, col=cols,
     xlab="Observed growth rate (1/hr)",
     ylab="OOF predicted growth rate (1/hr)",
     main="OOF predicted vs observed")
abline(0, 1, lty=2, lwd=2)

plot(pred_oof, resid_oof, pch=16, col="grey50",
     xlab="OOF fitted", ylab="Residual",
     main="Residuals vs fitted (OOF)")
abline(h=0, lty=2)

hist(resid_oof, breaks=40, col="grey90", border="grey60",
     main="Residuals (OOF)", xlab="Residual")

par(mfrow=c(1,1))
```

## Classification performance: ROC and AUC analysis

To evaluate whether the replication signal can separate fast vs slow growth, we turned growth rate into a binary label: fast is the top 25% of observed growth rates, slow the remaining 75%.

We then used the OOF predicted growth rates as a continuous score and computed an ROC curve across all thresholds. The AUC summarizes discrimination: it is the probability that a randomly chosen fast sample gets a higher score than a randomly chosen slow sample ($AUC=0.5$ is random, $AUC \to 1$ is strong separation).

The ROC curve lies consistently above the diagonal, indicating genuine out-of-sample discriminative signal. However, the separation is only moderate (AUC ≈ 0.69): many fast and slow samples overlap in predicted scores, so achieving high sensitivity requires accepting a non-trivial false-positive rate. Overall, $\Delta_{ori}$ captures enough replication-related information to rank growth phenotypes better than chance, but it is not a strong standalone classifier in this dataset.

```{r roc_auc, echo=FALSE}
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")
library(pROC)

# Use the OOF predictions already computed in section 17
oof_all <- df
oof_all$pred_oof <- pred_oof

# "Fast" = top quartile by observed growth rate
q_fast <- 0.75
thr_fast <- as.numeric(quantile(oof_all$growth_rate, q_fast, na.rm = TRUE))
oof_all$fast <- oof_all$growth_rate >= thr_fast

# ROC + AUC (OOF scores = out-of-sample discrimination)
roc_obj <- pROC::roc(response = oof_all$fast, predictor = oof_all$pred_oof, quiet = TRUE)
auc_val <- as.numeric(pROC::auc(roc_obj))
cat("\nAUC (fast = top 25% by observed growth):", auc_val, "\n")

# Plot (force standard ROC axes in [0,1]x[0,1])
plot(1 - roc_obj$specificities, roc_obj$sensitivities, type="l", lwd=2,
     xlab="(1 - Specificity)",
     ylab="Sensitivity",
     main=paste0("ROC (fast=top ", q_fast*100, "%). AUC=", round(auc_val, 3)),
     xlim=c(0,1), ylim=c(0,1))
abline(0, 1, lty=2)
```
## Prediction of growth rates for unlabeled samples.
Samples with missing growth-rate measurements were identified using the sentinel value $growth_rate = 1$. For these samples, we predicted growth rate from the ori-anchored replication contrast $\Delta_{ori}$ using the final regression model fitted on all labeled samples ($growth_rate \sim \Delta_{ori}$). We also computed 95% prediction intervals to reflect sample-level uncertainty.
For unlabeled samples that also show a statistically supported circular signal ($q_{full}<0.05$), we additionally generated predictions from the model fitted only on the significant subset (same specification, trained on high-confidence samples). The output table reports the final prediction, its interval, and which model generated it.

```{r predict_unknown, echo=FALSE}
unknown <- merged_results2 %>%
  dplyr::filter(is.na(growth_rate) | growth_rate == 1) %>%   # unlabeled = NA or sentinel 1
  dplyr::filter(is.finite(delta_ori), is.finite(A))

# Base predictions (ALL model)
pred_all <- predict(fit_all, newdata = unknown,
                    interval = "prediction", level = 0.95)

unknown$pred_final    <- pred_all[, "fit"]
unknown$pred_final_lo <- pred_all[, "lwr"]
unknown$pred_final_hi <- pred_all[, "upr"]
unknown$pred_source   <- "ALL"

# If q_full < 0.05, overwrite with sig-only model (when available)
mask_sig <- !is.na(unknown$q_full) & unknown$q_full < 0.05

pred_sig <- predict(fit_sigq, newdata = unknown[mask_sig, , drop = FALSE],
                    interval = "prediction", level = 0.95)

unknown$pred_final[mask_sig]    <- pred_sig[, "fit"]
unknown$pred_final_lo[mask_sig] <- pred_sig[, "lwr"]
unknown$pred_final_hi[mask_sig] <- pred_sig[, "upr"]
unknown$pred_source[mask_sig]   <- "sig_q"

# Output (top 20 by predicted growth)
unknown %>%
  dplyr::select(sample_id, q_full, delta_ori, A,
                pred_final, pred_final_lo, pred_final_hi, pred_source) %>%
  dplyr::arrange(dplyr::desc(pred_final)) %>%
  head(20)
  tibble(
  n_unknown = nrow(unknown),
  n_sig_q   = sum(unknown$pred_source == "sig_q"),
  n_all     = sum(unknown$pred_source == "ALL"),
  pred_min  = min(unknown$pred_final, na.rm=TRUE),
  pred_med  = median(unknown$pred_final, na.rm=TRUE),
  pred_max  = max(unknown$pred_final, na.rm=TRUE)
)
```
## Visualization of circular expression profiles

To make the circular model easier to interpret, we plotted three representative samples: (i) a fast-growing sample with a significant circular replication signal, (ii) a slow / weak-signal sample, and (iii) one unlabeled sample (missing growth rate) when available.

For each sample we show three panels:

Expression vs genomic angle ($\theta$): binned mean logTPM across the genome with the fitted sinusoid, plus reference lines at $\theta_{ori}$ and $\theta_{ori}+\pi$ (opposite side), and the fitted $\theta_{max}$ / $\theta_{min}$.  
Polar view: the same information mapped to a circle to emphasize genome continuity.  
Compact summary: signal strength and orientation ($A$, $\Delta=2A$, $\Delta_{ori}$), model significance ($q_{full}$), observed growth rate when available, and the predicted growth rate with a 95% prediction interval. Predictions follow the same rule used before: if $q_{full}<0.05$ we use the $sig\_q$ model; otherwise we use the ALL model.

These plots provide an intuitive link between the fitted circular expression gradient and how $\Delta_{ori}$ is used to predict growth.

```{r visualizations, echo=FALSE}
# pick 3 examples: fast+significant, slow/weak, and one unlabeled (if exists)
mask_q <- !is.na(known$q_full) & known$q_full < 0.05

id_fast <- known %>%
  dplyr::filter(mask_q) %>%
  dplyr::arrange(dplyr::desc(growth_rate)) %>%
  dplyr::slice(1) %>%
  dplyr::pull(sample_id)
if (length(id_fast) == 0) {
  id_fast <- known %>% dplyr::arrange(dplyr::desc(growth_rate)) %>% dplyr::slice(1) %>% dplyr::pull(sample_id)
}

id_slow <- known %>%
  dplyr::filter(!mask_q) %>%
  dplyr::arrange(growth_rate) %>%
  dplyr::slice(1) %>%
  dplyr::pull(sample_id)
if (length(id_slow) == 0) {
  id_slow <- known %>% dplyr::arrange(growth_rate) %>% dplyr::slice(1) %>% dplyr::pull(sample_id)
}

id_unk <- unknown %>%
  dplyr::arrange(dplyr::desc(delta_ori)) %>%
  dplyr::slice(1) %>%
  dplyr::pull(sample_id)
if (length(id_unk) == 0) id_unk <- NA_character_

plot_demo <- function(sid, tag="") {
  df <- bin_expr %>% dplyr::filter(sample_id == sid) %>% dplyr::arrange(theta_bin)
  rr <- merged_results2 %>% dplyr::filter(sample_id == sid) %>% dplyr::slice(1)

  # circular fit for visualization
  fit_circ <- lm(y ~ cos(theta_bin) + sin(theta_bin), data = df, weights = df$n_genes)

  th_grid <- seq(0, 2*pi, length.out = 600)
  yhat <- predict(fit_circ, newdata = data.frame(theta_bin = th_grid))

  # growth prediction (same tier rule as section 19)
  use_sig <- exists("fit_sigq") && !is.null(fit_sigq) && !is.na(rr$q_full) && rr$q_full < 0.05
  fit_pred <- if (use_sig) fit_sigq else fit_all
  pred <- predict(fit_pred, newdata = data.frame(delta_ori = rr$delta_ori),
                  interval = "prediction", level = 0.95)

  gr_obs <- rr$growth_rate
  gr_txt <- if (!is.na(gr_obs) && gr_obs != 1) sprintf("Observed growth_rate: %.3f", gr_obs) else "Observed growth_rate: NA"
  src_txt <- if (use_sig) "Prediction model: sig_q" else "Prediction model: ALL"

  par(mfrow = c(1,3), mar = c(4,4,3,1))

  # (1) expression vs theta
  plot(df$theta_bin, df$y, pch = 16, col = "grey60",
       xlab = "theta (radians)", ylab = "mean logTPM (bin)",
       main = paste0(tag, sid))
  lines(th_grid, yhat, lwd = 3)
  abline(v = theta_ori, lty = 2, lwd = 2)
  abline(v = (theta_ori + pi) %% (2*pi), lty = 3, lwd = 2)
  abline(v = rr$theta_max, lty = 2, col = "black")
  abline(v = rr$theta_min, lty = 3, col = "black")

  # (2) polar view (simple rescaling to radius)
  r_bin <- (df$y - min(yhat)) / (max(yhat) - min(yhat) + 1e-12)
  r_bin <- 0.25 + 0.75 * r_bin
  r_fit <- (yhat - min(yhat)) / (max(yhat) - min(yhat) + 1e-12)
  r_fit <- 0.25 + 0.75 * r_fit

  plot(0, 0, type = "n", asp = 1, xlim = c(-1.1,1.1), ylim = c(-1.1,1.1),
       xlab = "", ylab = "", main = "Polar view")
  t0 <- seq(0, 2*pi, length.out = 400)
  lines(cos(t0), sin(t0), col = "grey80")
  points(r_bin*cos(df$theta_bin), r_bin*sin(df$theta_bin), pch = 16, col = "grey60", cex = 0.7)
  lines(r_fit*cos(th_grid), r_fit*sin(th_grid), lwd = 3)
  points(cos(theta_ori), sin(theta_ori), pch = 8, cex = 1.2)
  points(cos((theta_ori+pi)%%(2*pi)), sin((theta_ori+pi)%%(2*pi)), pch = 4, cex = 1.2)

  # (3) compact summary
  plot.new(); title(main = "Summary")
  txt <- c(
    gr_txt,
    sprintf("q_full: %.3g", rr$q_full),
    sprintf("A: %.3f | delta: %.3f | delta_ori: %.3f", rr$A, rr$delta, rr$delta_ori),
    "",
    src_txt,
    sprintf("Predicted: %.3f  [%.3f, %.3f]", pred[1,"fit"], pred[1,"lwr"], pred[1,"upr"])
  )
  text(0, 1, adj = c(0,1), labels = paste(txt, collapse = "\n"), cex = 0.9)

  par(mfrow = c(1,1))
}

plot_demo(id_fast, tag = "FAST + significant: ")
plot_demo(id_slow, tag = "SLOW / weak-signal: ")
if (!is.na(id_unk)) plot_demo(id_unk, tag = "UNLABELED: ")
```
